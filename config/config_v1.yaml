data:
  input_size: 512
  channels: 3
  batch_size: 1
  train_split: 0.8
  validation_split: 0.2
  random_state: 42
  resolution: 0.03
  overlap_percentage: 0.25
  line_width: 5
  tiff_bands: 3
  zip_paths:
    images: "/content/drive/MyDrive/tiles/images.zip"
    masks: "/content/drive/MyDrive/masks/masks.zip"
  dataset_info:
    train_size: 2252
    val_size: 563

model:
  initial_filters: 64
  depth: 4
  dropout_rate: 0.25
  learning_rate: 0.0005

training:
  epochs: 100
  steps_per_epoch: 141  # train_size // batch_size
  validation_steps: 36 # ceil(val_size / batch_size)
  early_stopping_patience: 15
  reduce_lr_patience: 8
  min_lr: 0.00001
  class_weights: [0.5629221814593915, 4.4731616768777185]
  optimal_threshold: 0.465

paths:
  train_images: "/media/vassarml/HDD/dinesh/SLIS/dinesh_train/0610/train_data"
  train_masks: "/media/vassarml/HDD/dinesh/SLIS/dinesh_train/0610/train_mask"
  val_images: "/data/home/gpuserver/vinay/building_data_sobel/train_data"
  val_masks: "/data/home/gpuserver/vinay/building_data_sobel/train_masks"
  temp: "/media/vassarml/HDD/vinay/attention_unet/temp"
  model_save: "/media/vassarml/HDD/vinay/attention_unet/models/"
  logs: "/media/vassarml/HDD/vinay/attention_unet/logs"

